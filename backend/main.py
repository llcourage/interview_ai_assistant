from fastapi import FastAPI, HTTPException, File, UploadFile, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import os
import json
import platform
from pathlib import Path
from dotenv import load_dotenv
from vision import analyze_image
from speech import transcribe_audio
from openai import AsyncOpenAI
from datetime import timedelta
from auth_supabase import (
    User, UserRegister, UserLogin, Token,
    register_user, login_user, get_current_active_user
)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
load_dotenv('.env.plans')  # åŠ è½½ Plan API Keys

# ğŸ”‘ è·å– Electron é…ç½®æ–‡ä»¶è·¯å¾„
def get_electron_config_path():
    """è·å– Electron é…ç½®æ–‡ä»¶è·¯å¾„"""
    system = platform.system()
    app_name = "AI Interview Assistant"  # éœ€è¦ä¸ Electron app åç§°åŒ¹é…
    
    if system == "Windows":
        appdata = os.getenv("APPDATA")
        if appdata:
            return Path(appdata) / app_name / "config.json"
    elif system == "Darwin":  # macOS
        home = Path.home()
        return home / "Library" / "Application Support" / app_name / "config.json"
    else:  # Linux
        home = Path.home()
        return home / ".config" / app_name.lower().replace(" ", "-") / "config.json"
    
    return None

# ğŸ”‘ ä»é…ç½®æ–‡ä»¶è¯»å– API Key
def get_api_key_from_config():
    """ä» Electron é…ç½®æ–‡ä»¶è¯»å– API Key"""
    config_path = get_electron_config_path()
    if config_path and config_path.exists():
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                api_key = config.get('apiKey')
                if api_key:
                    print(f"âœ… ä»é…ç½®æ–‡ä»¶è¯»å– API Key: {config_path}")
                    return api_key
        except Exception as e:
            print(f"âš ï¸ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    return None

# ğŸ”‘ è·å– API Keyï¼ˆä¼˜å…ˆä»é…ç½®æ–‡ä»¶ï¼Œå…¶æ¬¡ä»ç¯å¢ƒå˜é‡ï¼‰
def get_api_key(plan_type: str = "starter"):
    """
    è·å– API Keyï¼Œä¼˜å…ˆçº§ï¼šé…ç½®æ–‡ä»¶ > ç¯å¢ƒå˜é‡
    plan_type: "starter" | "normal" | "high"
    """
    # Starter Plan: ä»é…ç½®æ–‡ä»¶è¯»å–ç”¨æˆ·è‡ªå®šä¹‰çš„ API Key
    if plan_type == "starter":
        api_key = get_api_key_from_config()
        if api_key:
            return api_key, None
        return None, None
    
    # Normal Plan: GPT-4o Mini (ä½¿ç”¨ OpenAI API)
    elif plan_type == "normal":
        api_key = os.getenv("OPENAI_API_KEY")
        base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        if api_key and api_key != "your_openai_api_key_here":
            return api_key, base_url
        return None, None
    
    # High Plan: ChatGPT (OpenAI)
    elif plan_type == "high":
        api_key = os.getenv("OPENAI_API_KEY")
        base_url = os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        if api_key and api_key != "your_openai_api_key_here":
            return api_key, base_url
        return None, None
    
    return None, None

# ğŸ”‘ åŠ¨æ€è·å– API Key çš„å‡½æ•°ï¼ˆæ”¯æŒ plan ç±»å‹ï¼‰
def get_current_api_key(plan_type: str = "starter"):
    """æ¯æ¬¡è°ƒç”¨æ—¶é‡æ–°è¯»å– API Keyï¼ˆæ”¯æŒåŠ¨æ€æ›´æ–°ï¼‰
    
    Args:
        plan_type: "starter" | "normal" | "high"
            - starter: ç”¨æˆ·è‡ªå®šä¹‰ API Keyï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
            - normal: DeepSeek API
            - high: ChatGPT API
    """
    api_key, base_url = get_api_key(plan_type)
    return api_key, base_url

# âš ï¸ ä¸å†ä½¿ç”¨å…¨å±€å®¢æˆ·ç«¯ï¼Œè€Œæ˜¯åœ¨æ¯ä¸ªè¯·æ±‚ä¸­åŠ¨æ€åˆ›å»º

app = FastAPI(
    title="AI Interview Assistant API",
    description="AI é¢è¯•åŠ©æ‰‹åç«¯æœåŠ¡",
    version="1.0.0"
)

# é…ç½® CORS - å…è®¸å‰ç«¯è®¿é—®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒåº”è¯¥é™åˆ¶å…·ä½“çš„åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è¯·æ±‚æ¨¡å‹
class VisionQueryRequest(BaseModel):
    image_base64: str | list[str]  # æ”¯æŒå•å¼ æˆ–å¤šå¼ å›¾ç‰‡
    prompt: str = "" # é»˜è®¤ä¸ºç©ºï¼Œä½¿ç”¨ vision.py ä¸­çš„æ–° Prompt
    plan: str = "starter"  # "starter" | "normal" | "high"

class TextChatRequest(BaseModel):
    user_input: str  # ç”¨æˆ·è¾“å…¥
    context: str = ""  # å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
    plan: str = "starter"  # "starter" | "normal" | "high"

# å“åº”æ¨¡å‹
class VisionQueryResponse(BaseModel):
    answer: str
    success: bool = True
    error: str = ""

class TextChatResponse(BaseModel):
    answer: str
    success: bool = True
    error: str = ""

class SpeechToTextResponse(BaseModel):
    text: str
    language: str = ""
    duration: float = 0.0
    success: bool = True
    error: str = ""

@app.get("/")
async def root():
    """æ ¹è·¯å¾„ - å¥åº·æ£€æŸ¥"""
    return {
        "status": "running",
        "message": "AI Interview Assistant API is running",
        "version": "1.0.0"
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return {"status": "healthy"}

# ========== è®¤è¯ç›¸å…³ API ==========

@app.post("/api/register", response_model=Token, tags=["è®¤è¯"])
async def register(user_data: UserRegister):
    """ç”¨æˆ·æ³¨å†Œ"""
    return await register_user(user_data.email, user_data.password)


@app.post("/api/login", response_model=Token, tags=["è®¤è¯"])
async def login(user_data: UserLogin):
    """ç”¨æˆ·ç™»å½•"""
    return await login_user(user_data.email, user_data.password)


@app.get("/api/me", response_model=User, tags=["è®¤è¯"])
async def read_users_me(current_user: User = Depends(get_current_active_user)):
    """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
    return current_user

# ========== AI åŠŸèƒ½ API ==========

@app.post("/api/vision_query", response_model=VisionQueryResponse)
async def vision_query(request: VisionQueryRequest):
    """
    è§†è§‰åˆ†ææ¥å£
    
    æ¥æ”¶ base64 ç¼–ç çš„å›¾ç‰‡ï¼Œè°ƒç”¨ OpenAI Vision API è¿›è¡Œåˆ†æ
    """
    try:
        # ğŸ”‘ æ ¹æ® plan ç±»å‹è·å–å¯¹åº”çš„ API Key å’Œ Base URL
        plan_type = request.plan or "starter"
        api_key, base_url = get_current_api_key(plan_type)
        
        if not api_key:
            plan_name = {"starter": "Starter", "normal": "Normal", "high": "High"}.get(plan_type, "Starter")
            error_msg = f"âš ï¸ {plan_name} Plan API Key not configured!"
            if plan_type == "starter":
                error_msg += "\n\nPlease configure your OpenAI API Key in settings."
            return VisionQueryResponse(
                answer=error_msg,
                success=False,
                error="API Key not configured"
            )
        
        # ğŸ”‘ ä½¿ç”¨å¯¹åº”çš„ API Key å’Œ Base URL åˆ›å»ºå®¢æˆ·ç«¯
        dynamic_client = AsyncOpenAI(
            api_key=api_key,
            base_url=base_url or "https://api.openai.com/v1"
        )
        
        # ğŸ¤– æ ¹æ® plan ç±»å‹é€‰æ‹©æ¨¡å‹
        model_map = {
            "starter": os.getenv("OPENAI_MODEL", "gpt-4o"),  # Starter: ç”¨æˆ·è‡ªå·±çš„ OpenAI æ¨¡å‹
            "normal": "gpt-4o-mini",  # Normal: GPT-4o Miniï¼ˆä¾¿å®œä¸”æ”¯æŒ Visionï¼‰
            "high": "gpt-4o"  # High: GPT-4oï¼ˆæœ€å¼ºæ€§èƒ½ï¼‰
        }
        model = model_map.get(plan_type, "gpt-4o")
        
        print(f"ğŸ¯ Plan: {plan_type}, Model: {model}, Base URL: {base_url}")
        
        # è°ƒç”¨è§†è§‰åˆ†æå‡½æ•°ï¼ˆéœ€è¦ä¼ å…¥å®¢æˆ·ç«¯å’Œæ¨¡å‹ï¼‰
        answer = await analyze_image(
            image_base64=request.image_base64,
            prompt=request.prompt,
            client=dynamic_client,
            model=model
        )
        
        return VisionQueryResponse(
            answer=answer,
            success=True
        )
        
    except Exception as e:
        error_message = str(e)
        print(f"âŒ è§†è§‰åˆ†æå¤±è´¥: {error_message}")
        
        return VisionQueryResponse(
            answer=f"åˆ†æå¤±è´¥: {error_message}",
            success=False,
            error=error_message
        )

@app.post("/api/text_chat", response_model=TextChatResponse)
async def text_chat(request: TextChatRequest):
    """
    æ–‡å­—å¯¹è¯æ¥å£
    
    æ¥æ”¶ç”¨æˆ·è¾“å…¥å’Œä¸Šä¸‹æ–‡ï¼Œè°ƒç”¨ OpenAI GPT è¿›è¡Œå¯¹è¯
    """
    try:
        # ğŸ”‘ æ ¹æ® plan ç±»å‹è·å–å¯¹åº”çš„ API Key å’Œ Base URL
        plan_type = request.plan or "starter"
        api_key, base_url = get_current_api_key(plan_type)
        
        if not api_key:
            plan_name = {"starter": "Starter", "normal": "Normal", "high": "High"}.get(plan_type, "Starter")
            error_msg = f"âš ï¸ {plan_name} Plan API Key not configured!"
            if plan_type == "starter":
                error_msg += "\n\nPlease configure your OpenAI API Key in settings."
            return TextChatResponse(
                answer=error_msg,
                success=False,
                error="API Key not configured"
            )
        
        # ğŸ”‘ ä½¿ç”¨å¯¹åº”çš„ API Key å’Œ Base URL åˆ›å»ºå®¢æˆ·ç«¯
        dynamic_client = AsyncOpenAI(
            api_key=api_key,
            base_url=base_url or "https://api.openai.com/v1"
        )
        
        # æ„å»ºæ¶ˆæ¯
        messages = []
        
        # æ·»åŠ ç³»ç»Ÿæç¤ºï¼ˆé’ˆå¯¹é¢è¯•åŠ©æ‰‹åœºæ™¯ï¼‰
        messages.append({
            "role": "system",
            "content": """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯é¢è¯•åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. å›ç­”æŠ€æœ¯é—®é¢˜ï¼Œæä¾›æ¸…æ™°çš„è§£é‡Šå’Œä»£ç ç¤ºä¾‹
2. å¸®åŠ©ç”¨æˆ·ç†è§£é¢è¯•é¢˜çš„è§£é¢˜æ€è·¯
3. æä¾›æœ€ä½³å®è·µå’Œä¼˜åŒ–å»ºè®®
4. ä¿æŒç®€æ´ã€ä¸“ä¸šçš„å›ç­”é£æ ¼

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä»£ç é»˜è®¤ä½¿ç”¨ Pythonã€‚"""
        })
        
        # ğŸš¨ å¦‚æœæœ‰ä¸Šä¸‹æ–‡ï¼Œæˆªæ–­åˆ°æœ€è¿‘ 10 è½®å¯¹è¯
        if request.context:
            # æŒ‰åŒæ¢è¡Œç¬¦åˆ†å‰²å¯¹è¯
            context_parts = request.context.strip().split('\n\n')
            
            # ğŸš¨ åªä¿ç•™æœ€è¿‘ 10 è½®å¯¹è¯ï¼ˆæ¯è½®åŒ…å« User å’Œ AIï¼‰
            max_conversations = 10
            if len(context_parts) > max_conversations:
                truncated_context = '\n\n'.join(context_parts[-max_conversations:])
                print(f"ğŸ“Š ä¸Šä¸‹æ–‡æˆªæ–­: {len(context_parts)} è½® -> {max_conversations} è½®")
            else:
                truncated_context = request.context
            
            messages.append({
                "role": "system",
                "content": f"ä»¥ä¸‹æ˜¯ä¹‹å‰çš„å¯¹è¯å†å²ï¼ˆæœ€è¿‘ {min(len(context_parts), max_conversations)} è½®ï¼‰ï¼š\n\n{truncated_context}"
            })
        
        # æ·»åŠ ç”¨æˆ·å½“å‰è¾“å…¥
        messages.append({
            "role": "user",
            "content": request.user_input
        })
        
        # ğŸ¤– æ ¹æ® plan ç±»å‹é€‰æ‹©æ¨¡å‹
        model_map = {
            "starter": os.getenv("OPENAI_MODEL", "gpt-4o"),  # Starter: ç”¨æˆ·è‡ªå·±çš„ OpenAI æ¨¡å‹
            "normal": "gpt-4o-mini",  # Normal: GPT-4o Miniï¼ˆä¾¿å®œä¸”æ”¯æŒå¯¹è¯ï¼‰
            "high": "gpt-4o"  # High: GPT-4oï¼ˆæœ€å¼ºæ€§èƒ½ï¼‰
        }
        model = model_map.get(plan_type, "gpt-4o")
        
        print(f"ğŸ¯ Plan: {plan_type}, Model: {model}, Base URL: {base_url}")
        print(f"ğŸ“ ç”¨æˆ·è¾“å…¥: {request.user_input[:100]}...")
        
        response = await dynamic_client.chat.completions.create(
            model=model,
            messages=messages,
            max_tokens=2000,
            temperature=0.7
        )
        
        answer = response.choices[0].message.content
        print(f"âœ… å¯¹è¯å®Œæˆï¼Œå›å¤é•¿åº¦: {len(answer)} å­—ç¬¦")
        
        return TextChatResponse(
            answer=answer,
            success=True
        )
        
    except Exception as e:
        error_message = str(e)
        print(f"âŒ å¯¹è¯å¤±è´¥: {error_message}")
        
        return TextChatResponse(
            answer=f"å¯¹è¯å¤±è´¥: {error_message}",
            success=False,
            error=error_message
        )

@app.post("/api/speech_to_text", response_model=SpeechToTextResponse)
async def speech_to_text(
    audio: UploadFile = File(...),
    language: str = "zh"
):
    """
    è¯­éŸ³è½¬æ–‡å­—æ¥å£
    
    æ¥æ”¶éŸ³é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨æœ¬åœ° Whisper æ¨¡å‹è½¬æ¢ä¸ºæ–‡å­—
    """
    try:
        # è¯»å–éŸ³é¢‘æ•°æ®
        audio_data = await audio.read()
        
        if len(audio_data) == 0:
            return SpeechToTextResponse(
                text="",
                success=False,
                error="éŸ³é¢‘æ–‡ä»¶ä¸ºç©º"
            )
        
        print(f"ğŸ¤ æ”¶åˆ°éŸ³é¢‘æ–‡ä»¶: {audio.filename}, å¤§å°: {len(audio_data)} å­—èŠ‚")
        
        # è°ƒç”¨è¯­éŸ³è½¬æ–‡å­—
        result = await transcribe_audio(audio_data, language=language)
        
        return SpeechToTextResponse(
            text=result["text"],
            language=result.get("language", ""),
            duration=result.get("duration", 0.0),
            success=True
        )
        
    except Exception as e:
        error_message = str(e)
        print(f"âŒ è¯­éŸ³è½¬æ–‡å­—å¤±è´¥: {error_message}")
        
        return SpeechToTextResponse(
            text="",
            success=False,
            error=error_message
        )

@app.post("/api/test")
async def test_endpoint(data: dict):
    """æµ‹è¯•æ¥å£"""
    return {
        "message": "Test successful",
        "received": data
    }

if __name__ == "__main__":
    host = os.getenv("HOST", "127.0.0.1")
    port = int(os.getenv("PORT", 8000))
    
    print("=" * 60)
    print("ğŸ”¥ AI é¢è¯•åŠ©æ‰‹åç«¯æœåŠ¡")
    print("=" * 60)
    print(f"ğŸ“¡ æœåŠ¡åœ°å€: http://{host}:{port}")
    print(f"ğŸ“š API æ–‡æ¡£: http://{host}:{port}/docs")
    print(f"ğŸ”§ å¥åº·æ£€æŸ¥: http://{host}:{port}/health")
    print("=" * 60)
    
    uvicorn.run(
        "main:app",
        host=host,
        port=port,
        reload=True,
        log_level="info"
    )


