import os
import base64
from io import BytesIO
from PIL import Image
from openai import AsyncOpenAI
from dotenv import load_dotenv

load_dotenv()

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = AsyncOpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url=os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
)

async def analyze_image(image_base64: str | list[str], prompt: str = None) -> str:
    """
    ä½¿ç”¨ OpenAI Vision API åˆ†æå›¾ç‰‡ï¼ˆæ”¯æŒå¤šå¼ å›¾ç‰‡ï¼‰
    
    Args:
        image_base64: Base64 ç¼–ç çš„å›¾ç‰‡æˆ–å›¾ç‰‡åˆ—è¡¨
        prompt: åˆ†ææç¤ºè¯ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        str: AI åˆ†æç»“æœ
    """
    try:
        # é»˜è®¤æç¤ºè¯ - ç»“æ„åŒ–é¢è¯•é¢˜ç‰ˆ
        if not prompt:
            prompt = """è¯·ä»”ç»†é˜…è¯»æˆªå›¾ä¸­çš„é¢˜ç›®ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ 5 ä¸ªéƒ¨åˆ†è¿›è¡Œå›å¤ï¼Œä¸è¦åŒ…å«å…¶ä»–å¤šä½™çš„æè¿°ï¼š

1ï¼‰é—®é¢˜è§£é‡Šï¼ˆç®€çŸ­ï¼‰
ç®€è¦æ¦‚æ‹¬é¢˜ç›®è¦æ±‚ï¼Œä¸è¦å•°å—¦ã€‚

2ï¼‰Clarification Questions
åˆ—å‡º 3-5 ä¸ªé’ˆå¯¹é¢˜ç›®ç»†èŠ‚çš„å…³é”®æ¾„æ¸…é—®é¢˜ï¼ˆä¾‹å¦‚ï¼šè¾¹ç•Œæ¡ä»¶ã€è¾“å…¥è§„æ¨¡ã€å¼‚å¸¸æƒ…å†µï¼‰ã€‚ä¿æŒç®€çŸ­ã€‚

3ï¼‰è§£é¢˜æ€è·¯
åˆ†æ­¥éª¤è¯´æ˜æœ€ä¼˜è§£æ³•ï¼Œæ¸…æ™°æ˜äº†ã€‚

4ï¼‰ä»£ç 
```python
# åœ¨æ­¤æä¾›å®Œæ•´çš„ Python ä»£ç ï¼ŒåŒ…å«å…³é”®æ³¨é‡Š
```

5ï¼‰è§£é‡Š
å¯¹ä»£ç çš„å…³é”®é€»è¾‘è¿›è¡Œç®€è¦è§£é‡Šï¼ŒåŒ…æ‹¬æ—¶é—´/ç©ºé—´å¤æ‚åº¦åˆ†æã€‚

âš ï¸ ç¦æ­¢äº‹é¡¹ï¼š
- ä¸è¦å†™ "é—®é¢˜æè¿°"ã€"ç¤ºä¾‹"ã€"çº¦æŸæ¡ä»¶" ç« èŠ‚ã€‚
- ä¸è¦å†™ "è¿™å¼ å›¾ç‰‡å±•ç¤ºäº†..." ç­‰åºŸè¯ã€‚
- ä¿æŒå›ç­”ä¸“ä¸šã€ç´§å‡‘ã€‚"""

        # è·å–æ¨¡å‹åç§°
        model = os.getenv("OPENAI_MODEL", "gpt-4o")
        
        # å°†å•å¼ å›¾ç‰‡è½¬ä¸ºåˆ—è¡¨
        if isinstance(image_base64, str):
            image_list = [image_base64]
        else:
            image_list = image_base64
        
        print(f"ğŸ¤– è°ƒç”¨æ¨¡å‹: {model}")
        print(f"ğŸ“¸ å›¾ç‰‡æ•°é‡: {len(image_list)}")
        print(f"ğŸ“ æç¤ºè¯: {prompt[:100]}...")
        
        # æ„å»º content æ•°ç»„
        content = [{"type": "text", "text": prompt}]
        
        # æ·»åŠ æ‰€æœ‰å›¾ç‰‡
        for img_base64 in image_list:
            content.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/png;base64,{img_base64}",
                    "detail": "high"
                }
            })
        
        # è°ƒç”¨ OpenAI Vision API
        response = await client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user",
                    "content": content
                }
            ],
            max_tokens=3000,
            temperature=0.3
        )
        
        # æå–å›å¤
        answer = response.choices[0].message.content
        
        print(f"âœ… åˆ†æå®Œæˆï¼Œå›å¤é•¿åº¦: {len(answer)} å­—ç¬¦")
        
        return answer
        
    except Exception as e:
        error_msg = str(e)
        print(f"âŒ è§†è§‰åˆ†æå¤±è´¥: {error_msg}")
        
        # è¿”å›å‹å¥½çš„é”™è¯¯ä¿¡æ¯
        if "api_key" in error_msg.lower():
            return "âŒ API Key é”™è¯¯ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„ OPENAI_API_KEY"
        elif "rate_limit" in error_msg.lower():
            return "âŒ API è°ƒç”¨é¢‘ç‡è¶…é™ï¼Œè¯·ç¨åå†è¯•"
        elif "insufficient_quota" in error_msg.lower():
            return "âŒ API é…é¢ä¸è¶³ï¼Œè¯·æ£€æŸ¥ä½ çš„ OpenAI è´¦æˆ·ä½™é¢"
        else:
            return f"âŒ åˆ†æå¤±è´¥: {error_msg}"


def validate_image_base64(image_base64: str) -> bool:
    """
    éªŒè¯ Base64 å›¾ç‰‡æ˜¯å¦æœ‰æ•ˆ
    
    Args:
        image_base64: Base64 ç¼–ç çš„å›¾ç‰‡
        
    Returns:
        bool: æ˜¯å¦æœ‰æ•ˆ
    """
    try:
        # è§£ç  base64
        image_data = base64.b64decode(image_base64)
        
        # å°è¯•æ‰“å¼€å›¾ç‰‡
        image = Image.open(BytesIO(image_data))
        
        # æ£€æŸ¥å›¾ç‰‡æ ¼å¼
        if image.format not in ['PNG', 'JPEG', 'JPG', 'GIF', 'WEBP']:
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ å›¾ç‰‡éªŒè¯å¤±è´¥: {e}")
        return False


async def analyze_image_with_context(
    image_base64: str, 
    context: str = None,
    question_type: str = "general"
) -> dict:
    """
    å¸¦ä¸Šä¸‹æ–‡çš„å›¾ç‰‡åˆ†æ
    
    Args:
        image_base64: Base64 ç¼–ç çš„å›¾ç‰‡
        context: é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        question_type: é—®é¢˜ç±»å‹ï¼ˆalgorithm, system_design, coding, generalï¼‰
        
    Returns:
        dict: åŒ…å«åˆ†æç»“æœçš„å­—å…¸
    """
    # æ ¹æ®é—®é¢˜ç±»å‹è°ƒæ•´æç¤ºè¯
    prompt_templates = {
        "algorithm": "è¿™æ˜¯ä¸€é“ç®—æ³•é¢˜ã€‚è¯·åˆ†æé¢˜ç›®è¦æ±‚ï¼Œæä¾›è§£é¢˜æ€è·¯ã€æ—¶é—´å¤æ‚åº¦åˆ†æï¼Œå¹¶ç»™å‡ºä»£ç å®ç°ã€‚",
        "system_design": "è¿™æ˜¯ä¸€é“ç³»ç»Ÿè®¾è®¡é¢˜ã€‚è¯·åˆ†æéœ€æ±‚ï¼Œæä¾›æ¶æ„è®¾è®¡ã€æŠ€æœ¯é€‰å‹ï¼Œå¹¶è¯´æ˜è®¾è®¡ç†ç”±ã€‚",
        "coding": "è¿™æ˜¯ä¸€é“ç¼–ç¨‹é¢˜ã€‚è¯·åˆ†æé¢˜ç›®ï¼Œæä¾›ä»£ç å®ç°å’Œæµ‹è¯•ç”¨ä¾‹ã€‚",
        "general": "è¯·è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚"
    }
    
    prompt = prompt_templates.get(question_type, prompt_templates["general"])
    
    if context:
        prompt += f"\n\né¢å¤–ä¿¡æ¯: {context}"
    
    answer = await analyze_image(image_base64, prompt)
    
    return {
        "answer": answer,
        "question_type": question_type,
        "has_context": bool(context)
    }

