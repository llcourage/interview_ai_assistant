import os
import base64
from io import BytesIO
from PIL import Image
from openai import AsyncOpenAI
from dotenv import load_dotenv

load_dotenv()

# âš ï¸ ä¸å†åœ¨æ¨¡å—çº§åˆ«åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼Œæ”¹ä¸ºåœ¨å‡½æ•°ä¸­æ¥æ”¶åŠ¨æ€å®¢æˆ·ç«¯

async def analyze_image(image_base64: str | list[str], prompt: str = None, client: AsyncOpenAI = None, model: str = None) -> tuple[str, dict]:
    """
    ä½¿ç”¨ OpenAI Vision API åˆ†æå›¾ç‰‡ï¼ˆæ”¯æŒå¤šå¼ å›¾ç‰‡ï¼‰
    
    Args:
        image_base64: Base64 ç¼–ç çš„å›¾ç‰‡æˆ–å›¾ç‰‡åˆ—è¡¨
        prompt: åˆ†ææç¤ºè¯ï¼ˆå¯é€‰ï¼‰
        client: OpenAI å®¢æˆ·ç«¯ï¼ˆå¿…é¡»æä¾›ï¼‰
        model: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼ï¼‰
        
    Returns:
        str: AI åˆ†æç»“æœ
    """
    try:
        # ğŸ”‘ å¿…é¡»æä¾›å®¢æˆ·ç«¯
        if client is None:
            raise ValueError("Client must be provided")
        
        api_client = client
        # Default prompt - Structured interview question format
        if not prompt:
            prompt = """Please carefully read the problem in the screenshot.

Please strictly follow these 5 sections in your response, without any extra descriptions:

1) Problem Explanation (Brief)
Briefly summarize the problem requirements. Be concise.

2) Clarification Questions
List 3-5 key clarifying questions about the problem details (e.g., edge cases, input constraints, exceptions). Keep them brief.

3) Approach
Explain the optimal solution step by step, clearly and concisely.

4) Code
```python
# Provide complete Python code here with key comments
```

5) Explanation
Briefly explain the key logic of the code, including time/space complexity analysis.

âš ï¸ Prohibited:
- Do not write "Problem Description", "Examples", "Constraints" sections.
- Do not write phrases like "This image shows..." or other unnecessary text.
- Keep the response professional and concise."""

        # è·å–æ¨¡å‹åç§°ï¼ˆä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„æ¨¡å‹ï¼Œå…¶æ¬¡ç¯å¢ƒå˜é‡ï¼Œæœ€åé»˜è®¤å€¼ï¼‰
        if model is None:
            model = os.getenv("OPENAI_MODEL", "gpt-4o")
        
        # å°†å•å¼ å›¾ç‰‡è½¬ä¸ºåˆ—è¡¨
        if isinstance(image_base64, str):
            image_list = [image_base64]
        else:
            image_list = image_base64
        
        print(f"ğŸ¤– è°ƒç”¨æ¨¡å‹: {model}")
        print(f"ğŸ“¸ å›¾ç‰‡æ•°é‡: {len(image_list)}")
        print(f"ğŸ“ æç¤ºè¯: {prompt[:100]}...")
        
        # ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥å›¾ç‰‡æ•°æ®
        for idx, img_base64 in enumerate(image_list):
            print(f"ğŸ“· å›¾ç‰‡ {idx + 1} æ•°æ®é•¿åº¦: {len(img_base64)} å­—ç¬¦")
            print(f"ğŸ“· å›¾ç‰‡ {idx + 1} æ•°æ®å‰50å­—ç¬¦: {img_base64[:50]}")
        
        # æ„å»º content æ•°ç»„
        content = [{"type": "text", "text": prompt}]
        
        # æ·»åŠ æ‰€æœ‰å›¾ç‰‡
        for img_base64 in image_list:
            content.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/png;base64,{img_base64}",
                    "detail": "high"
                }
            })
        
        # è°ƒç”¨ OpenAI Vision API
        response = await api_client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user",
                    "content": content
                }
            ],
            max_tokens=3000,
            temperature=0.3
        )
        
        # æå–å›å¤
        answer = response.choices[0].message.content
        
        # æå– token ä½¿ç”¨é‡
        token_usage = {
            "input_tokens": response.usage.prompt_tokens,
            "output_tokens": response.usage.completion_tokens,
            "total_tokens": response.usage.total_tokens
        }
        
        print(f"âœ… åˆ†æå®Œæˆï¼Œå›å¤é•¿åº¦: {len(answer)} å­—ç¬¦")
        print(f"ğŸ“Š Token ä½¿ç”¨: {token_usage['total_tokens']} (è¾“å…¥: {token_usage['input_tokens']}, è¾“å‡º: {token_usage['output_tokens']})")
        
        return answer, token_usage
        
    except Exception as e:
        error_msg = str(e)
        print(f"âŒ è§†è§‰åˆ†æå¤±è´¥: {error_msg}")
        
        # è¿”å›å‹å¥½çš„é”™è¯¯ä¿¡æ¯
        error_message = ""
        if "api_key" in error_msg.lower() or "invalid api key" in error_msg.lower() or "authentication" in error_msg.lower():
            error_message = "âŒ API Key é”™è¯¯ã€‚"
            # æ£€æŸ¥æ˜¯å¦åœ¨ Vercel ç¯å¢ƒï¼ˆå¤šç§æ–¹å¼æ£€æµ‹ï¼‰
            import os
            is_vercel = os.getenv("VERCEL") or os.getenv("VERCEL_ENV") or os.getenv("NOW_REGION")
            
            if is_vercel:
                error_message += "\n\nè¯·åœ¨ Vercel Dashboard ä¸­æ£€æŸ¥ï¼š"
                error_message += "\n1. è¿›å…¥ Settings -> Environment Variables"
                error_message += "\n2. ç¡®è®¤ OPENAI_API_KEY å·²é…ç½®"
                error_message += "\n3. ç¡®ä¿ API Key å€¼æ­£ç¡®ï¼ˆä»¥ 'sk-' å¼€å¤´ï¼‰"
                error_message += "\n4. æ·»åŠ åéœ€è¦é‡æ–°éƒ¨ç½²åº”ç”¨"
            else:
                error_message += "\n\nè¯·æ£€æŸ¥ï¼š"
                error_message += "\n1. æœ¬åœ°ç¯å¢ƒï¼šæ£€æŸ¥ backend/.env æ–‡ä»¶ä¸­çš„ OPENAI_API_KEY"
                error_message += "\n2. Vercel ç¯å¢ƒï¼šæ£€æŸ¥ Vercel Dashboard -> Settings -> Environment Variables"
                error_message += "\n3. ç¡®ä¿ API Key ä»¥ 'sk-' å¼€å¤´ä¸”å®Œæ•´"
            error_message += "\n\nå¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œè¯·æŸ¥çœ‹æœåŠ¡å™¨æ—¥å¿—è·å–æ›´å¤šä¿¡æ¯ã€‚"
        elif "rate_limit" in error_msg.lower():
            error_message = "âŒ API è°ƒç”¨é¢‘ç‡è¶…é™ï¼Œè¯·ç¨åå†è¯•"
        elif "insufficient_quota" in error_msg.lower():
            error_message = "âŒ API é…é¢ä¸è¶³ï¼Œè¯·æ£€æŸ¥ä½ çš„ OpenAI è´¦æˆ·ä½™é¢"
        else:
            error_message = f"âŒ åˆ†æå¤±è´¥: {error_msg}"
        
        return error_message, {"input_tokens": 0, "output_tokens": 0, "total_tokens": 0}


def validate_image_base64(image_base64: str) -> bool:
    """
    éªŒè¯ Base64 å›¾ç‰‡æ˜¯å¦æœ‰æ•ˆ
    
    Args:
        image_base64: Base64 ç¼–ç çš„å›¾ç‰‡
        
    Returns:
        bool: æ˜¯å¦æœ‰æ•ˆ
    """
    try:
        # è§£ç  base64
        image_data = base64.b64decode(image_base64)
        
        # å°è¯•æ‰“å¼€å›¾ç‰‡
        image = Image.open(BytesIO(image_data))
        
        # æ£€æŸ¥å›¾ç‰‡æ ¼å¼
        if image.format not in ['PNG', 'JPEG', 'JPG', 'GIF', 'WEBP']:
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ å›¾ç‰‡éªŒè¯å¤±è´¥: {e}")
        return False


async def analyze_image_with_context(
    image_base64: str, 
    context: str = None,
    question_type: str = "general"
) -> dict:
    """
    å¸¦ä¸Šä¸‹æ–‡çš„å›¾ç‰‡åˆ†æ
    
    Args:
        image_base64: Base64 ç¼–ç çš„å›¾ç‰‡
        context: é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        question_type: é—®é¢˜ç±»å‹ï¼ˆalgorithm, system_design, coding, generalï¼‰
        
    Returns:
        dict: åŒ…å«åˆ†æç»“æœçš„å­—å…¸
    """
    # Adjust prompt based on question type
    prompt_templates = {
        "algorithm": "This is an algorithm problem. Please analyze the problem requirements, provide the solution approach, time complexity analysis, and code implementation.",
        "system_design": "This is a system design problem. Please analyze the requirements, provide architecture design, technology choices, and explain the design rationale.",
        "coding": "This is a coding problem. Please analyze the problem, provide code implementation and test cases.",
        "general": "Please analyze the content of this image in detail."
    }
    
    prompt = prompt_templates.get(question_type, prompt_templates["general"])
    
    if context:
        prompt += f"\n\nAdditional information: {context}"
    
    answer, token_usage = await analyze_image(image_base64, prompt)
    
    return {
        "answer": answer,
        "question_type": question_type,
        "has_context": bool(context),
        "token_usage": token_usage
    }

