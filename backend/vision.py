import os
import base64
from io import BytesIO
from PIL import Image
from openai import AsyncOpenAI
from dotenv import load_dotenv

load_dotenv()

# âš ï¸ ä¸å†åœ¨æ¨¡å—çº§åˆ«åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼Œæ”¹ä¸ºåœ¨å‡½æ•°ä¸­æ¥æ”¶åŠ¨æ€å®¢æˆ·ç«¯

async def analyze_image(image_base64: str | list[str], prompt: str = None, client: AsyncOpenAI = None, model: str = None) -> tuple[str, dict]:
    """
    ä½¿ç”¨ OpenAI Vision API åˆ†æå›¾ç‰‡ï¼ˆæ”¯æŒå¤šå¼ å›¾ç‰‡ï¼‰
    
    Args:
        image_base64: Base64 ç¼–ç çš„å›¾ç‰‡æˆ–å›¾ç‰‡åˆ—è¡¨
        prompt: åˆ†ææç¤ºè¯ï¼ˆå¯é€‰ï¼‰
        client: OpenAI å®¢æˆ·ç«¯ï¼ˆå¿…é¡»æä¾›ï¼‰
        model: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼ï¼‰
        
    Returns:
        str: AI åˆ†æç»“æœ
    """
    try:
        # ğŸ”‘ å¿…é¡»æä¾›å®¢æˆ·ç«¯
        if client is None:
            raise ValueError("Client must be provided")
        
        api_client = client
        # é»˜è®¤æç¤ºè¯ - ç»“æ„åŒ–é¢è¯•é¢˜ç‰ˆ
        if not prompt:
            prompt = """è¯·ä»”ç»†é˜…è¯»æˆªå›¾ä¸­çš„é¢˜ç›®ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ 5 ä¸ªéƒ¨åˆ†è¿›è¡Œå›å¤ï¼Œä¸è¦åŒ…å«å…¶ä»–å¤šä½™çš„æè¿°ï¼š

1ï¼‰é—®é¢˜è§£é‡Šï¼ˆç®€çŸ­ï¼‰
ç®€è¦æ¦‚æ‹¬é¢˜ç›®è¦æ±‚ï¼Œä¸è¦å•°å—¦ã€‚

2ï¼‰Clarification Questions
åˆ—å‡º 3-5 ä¸ªé’ˆå¯¹é¢˜ç›®ç»†èŠ‚çš„å…³é”®æ¾„æ¸…é—®é¢˜ï¼ˆä¾‹å¦‚ï¼šè¾¹ç•Œæ¡ä»¶ã€è¾“å…¥è§„æ¨¡ã€å¼‚å¸¸æƒ…å†µï¼‰ã€‚ä¿æŒç®€çŸ­ã€‚

3ï¼‰è§£é¢˜æ€è·¯
åˆ†æ­¥éª¤è¯´æ˜æœ€ä¼˜è§£æ³•ï¼Œæ¸…æ™°æ˜äº†ã€‚

4ï¼‰ä»£ç 
```python
# åœ¨æ­¤æä¾›å®Œæ•´çš„ Python ä»£ç ï¼ŒåŒ…å«å…³é”®æ³¨é‡Š
```

5ï¼‰è§£é‡Š
å¯¹ä»£ç çš„å…³é”®é€»è¾‘è¿›è¡Œç®€è¦è§£é‡Šï¼ŒåŒ…æ‹¬æ—¶é—´/ç©ºé—´å¤æ‚åº¦åˆ†æã€‚

âš ï¸ ç¦æ­¢äº‹é¡¹ï¼š
- ä¸è¦å†™ "é—®é¢˜æè¿°"ã€"ç¤ºä¾‹"ã€"çº¦æŸæ¡ä»¶" ç« èŠ‚ã€‚
- ä¸è¦å†™ "è¿™å¼ å›¾ç‰‡å±•ç¤ºäº†..." ç­‰åºŸè¯ã€‚
- ä¿æŒå›ç­”ä¸“ä¸šã€ç´§å‡‘ã€‚"""

        # è·å–æ¨¡å‹åç§°ï¼ˆä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„æ¨¡å‹ï¼Œå…¶æ¬¡ç¯å¢ƒå˜é‡ï¼Œæœ€åé»˜è®¤å€¼ï¼‰
        if model is None:
            model = os.getenv("OPENAI_MODEL", "gpt-4o")
        
        # å°†å•å¼ å›¾ç‰‡è½¬ä¸ºåˆ—è¡¨
        if isinstance(image_base64, str):
            image_list = [image_base64]
        else:
            image_list = image_base64
        
        print(f"ğŸ¤– è°ƒç”¨æ¨¡å‹: {model}")
        print(f"ğŸ“¸ å›¾ç‰‡æ•°é‡: {len(image_list)}")
        print(f"ğŸ“ æç¤ºè¯: {prompt[:100]}...")
        
        # ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥å›¾ç‰‡æ•°æ®
        for idx, img_base64 in enumerate(image_list):
            print(f"ğŸ“· å›¾ç‰‡ {idx + 1} æ•°æ®é•¿åº¦: {len(img_base64)} å­—ç¬¦")
            print(f"ğŸ“· å›¾ç‰‡ {idx + 1} æ•°æ®å‰50å­—ç¬¦: {img_base64[:50]}")
        
        # æ„å»º content æ•°ç»„
        content = [{"type": "text", "text": prompt}]
        
        # æ·»åŠ æ‰€æœ‰å›¾ç‰‡
        for img_base64 in image_list:
            content.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/png;base64,{img_base64}",
                    "detail": "high"
                }
            })
        
        # è°ƒç”¨ OpenAI Vision API
        response = await api_client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user",
                    "content": content
                }
            ],
            max_tokens=3000,
            temperature=0.3
        )
        
        # æå–å›å¤
        answer = response.choices[0].message.content
        
        # æå– token ä½¿ç”¨é‡
        token_usage = {
            "input_tokens": response.usage.prompt_tokens,
            "output_tokens": response.usage.completion_tokens,
            "total_tokens": response.usage.total_tokens
        }
        
        print(f"âœ… åˆ†æå®Œæˆï¼Œå›å¤é•¿åº¦: {len(answer)} å­—ç¬¦")
        print(f"ğŸ“Š Token ä½¿ç”¨: {token_usage['total_tokens']} (è¾“å…¥: {token_usage['input_tokens']}, è¾“å‡º: {token_usage['output_tokens']})")
        
        return answer, token_usage
        
    except Exception as e:
        error_msg = str(e)
        print(f"âŒ è§†è§‰åˆ†æå¤±è´¥: {error_msg}")
        
        # è¿”å›å‹å¥½çš„é”™è¯¯ä¿¡æ¯
        error_message = ""
        if "api_key" in error_msg.lower() or "invalid api key" in error_msg.lower() or "authentication" in error_msg.lower():
            error_message = "âŒ API Key é”™è¯¯ã€‚"
            # æ£€æŸ¥æ˜¯å¦åœ¨ Vercel ç¯å¢ƒï¼ˆå¤šç§æ–¹å¼æ£€æµ‹ï¼‰
            import os
            is_vercel = os.getenv("VERCEL") or os.getenv("VERCEL_ENV") or os.getenv("NOW_REGION")
            
            if is_vercel:
                error_message += "\n\nè¯·åœ¨ Vercel Dashboard ä¸­æ£€æŸ¥ï¼š"
                error_message += "\n1. è¿›å…¥ Settings -> Environment Variables"
                error_message += "\n2. ç¡®è®¤ OPENAI_API_KEY å·²é…ç½®"
                error_message += "\n3. ç¡®ä¿ API Key å€¼æ­£ç¡®ï¼ˆä»¥ 'sk-' å¼€å¤´ï¼‰"
                error_message += "\n4. æ·»åŠ åéœ€è¦é‡æ–°éƒ¨ç½²åº”ç”¨"
            else:
                error_message += "\n\nè¯·æ£€æŸ¥ï¼š"
                error_message += "\n1. æœ¬åœ°ç¯å¢ƒï¼šæ£€æŸ¥ backend/.env æ–‡ä»¶ä¸­çš„ OPENAI_API_KEY"
                error_message += "\n2. Vercel ç¯å¢ƒï¼šæ£€æŸ¥ Vercel Dashboard -> Settings -> Environment Variables"
                error_message += "\n3. ç¡®ä¿ API Key ä»¥ 'sk-' å¼€å¤´ä¸”å®Œæ•´"
            error_message += "\n\nå¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œè¯·æŸ¥çœ‹æœåŠ¡å™¨æ—¥å¿—è·å–æ›´å¤šä¿¡æ¯ã€‚"
        elif "rate_limit" in error_msg.lower():
            error_message = "âŒ API è°ƒç”¨é¢‘ç‡è¶…é™ï¼Œè¯·ç¨åå†è¯•"
        elif "insufficient_quota" in error_msg.lower():
            error_message = "âŒ API é…é¢ä¸è¶³ï¼Œè¯·æ£€æŸ¥ä½ çš„ OpenAI è´¦æˆ·ä½™é¢"
        else:
            error_message = f"âŒ åˆ†æå¤±è´¥: {error_msg}"
        
        return error_message, {"input_tokens": 0, "output_tokens": 0, "total_tokens": 0}


def validate_image_base64(image_base64: str) -> bool:
    """
    éªŒè¯ Base64 å›¾ç‰‡æ˜¯å¦æœ‰æ•ˆ
    
    Args:
        image_base64: Base64 ç¼–ç çš„å›¾ç‰‡
        
    Returns:
        bool: æ˜¯å¦æœ‰æ•ˆ
    """
    try:
        # è§£ç  base64
        image_data = base64.b64decode(image_base64)
        
        # å°è¯•æ‰“å¼€å›¾ç‰‡
        image = Image.open(BytesIO(image_data))
        
        # æ£€æŸ¥å›¾ç‰‡æ ¼å¼
        if image.format not in ['PNG', 'JPEG', 'JPG', 'GIF', 'WEBP']:
            return False
        
        return True
        
    except Exception as e:
        print(f"âŒ å›¾ç‰‡éªŒè¯å¤±è´¥: {e}")
        return False


async def analyze_image_with_context(
    image_base64: str, 
    context: str = None,
    question_type: str = "general"
) -> dict:
    """
    å¸¦ä¸Šä¸‹æ–‡çš„å›¾ç‰‡åˆ†æ
    
    Args:
        image_base64: Base64 ç¼–ç çš„å›¾ç‰‡
        context: é¢å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        question_type: é—®é¢˜ç±»å‹ï¼ˆalgorithm, system_design, coding, generalï¼‰
        
    Returns:
        dict: åŒ…å«åˆ†æç»“æœçš„å­—å…¸
    """
    # æ ¹æ®é—®é¢˜ç±»å‹è°ƒæ•´æç¤ºè¯
    prompt_templates = {
        "algorithm": "è¿™æ˜¯ä¸€é“ç®—æ³•é¢˜ã€‚è¯·åˆ†æé¢˜ç›®è¦æ±‚ï¼Œæä¾›è§£é¢˜æ€è·¯ã€æ—¶é—´å¤æ‚åº¦åˆ†æï¼Œå¹¶ç»™å‡ºä»£ç å®ç°ã€‚",
        "system_design": "è¿™æ˜¯ä¸€é“ç³»ç»Ÿè®¾è®¡é¢˜ã€‚è¯·åˆ†æéœ€æ±‚ï¼Œæä¾›æ¶æ„è®¾è®¡ã€æŠ€æœ¯é€‰å‹ï¼Œå¹¶è¯´æ˜è®¾è®¡ç†ç”±ã€‚",
        "coding": "è¿™æ˜¯ä¸€é“ç¼–ç¨‹é¢˜ã€‚è¯·åˆ†æé¢˜ç›®ï¼Œæä¾›ä»£ç å®ç°å’Œæµ‹è¯•ç”¨ä¾‹ã€‚",
        "general": "è¯·è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚"
    }
    
    prompt = prompt_templates.get(question_type, prompt_templates["general"])
    
    if context:
        prompt += f"\n\né¢å¤–ä¿¡æ¯: {context}"
    
    answer, token_usage = await analyze_image(image_base64, prompt)
    
    return {
        "answer": answer,
        "question_type": question_type,
        "has_context": bool(context),
        "token_usage": token_usage
    }

